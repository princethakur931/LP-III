# -*- coding: utf-8 -*-
"""prac4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yM5bUE92Tha3wA1jJvvi38KkwVf3V2HT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report

# --- 1. Load the Dataset ---
try:
    # Try reading as CSV first, as the error message suggests it might be a CSV file
    data = pd.read_csv('diabetes.xls')
    print("Dataset loaded successfully as CSV.")
    print(data.head())
except Exception as e:
    print(f"Error reading file as CSV: {e}")
    try:
        # If CSV fails, try reading as Excel with the specified engine
        data = pd.read_excel('diabetes.xls', engine='xlrd')
        print("Dataset loaded successfully as Excel.")
        print(data.head())
    except FileNotFoundError:
        print("Error: 'diabetes.xls' not found.")
        print("Please download it from: https://www.kaggle.com/datasets/abdallamahgoub/diabetes")
        exit()
    except Exception as e_excel:
        print(f"Error reading file as Excel: {e_excel}")
        print("Could not load the dataset. Please check the file and its format.")
        exit()


# --- 2. Data Preprocessing (Handling '0' values) ---
# This dataset famously uses '0' for impossible values (e.g., BMI=0).
# We replace these 0s with NaN (Not a Number) to handle them.
cols_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
data[cols_with_zeros] = data[cols_with_zeros].replace(0, np.nan)

# Now, we fill the NaN values with the *mean* of that column.
# This is a common data cleaning step called "imputation".
for col in cols_with_zeros:
    data[col].fillna(data[col].mean(), inplace=True)

# --- 3. Define Features (X) and Target (y) ---
# X = All columns except 'Outcome'
# y = The 'Outcome' column (0 = No Diabetes, 1 = Diabetes)
X = data.drop('Outcome', axis=1)
y = data['Outcome']

# --- 4. Split Data into Training and Testing Sets ---
# We use 80% for training and 20% for testing.
# random_state=42 ensures we get the same "random" split every time.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 5. Feature Scaling (CRITICAL FOR KNN) ---
# We scale the data so all features have a similar range.
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test) # Note: Only 'transform' on test data

# --- 6. Implement K-Nearest Neighbors (KNN) ---
# We'll choose K=7. It's a common practice to use an odd number to avoid ties.
k = 7
knn = KNeighborsClassifier(n_neighbors=k)

# Train the model on the scaled training data
knn.fit(X_train_scaled, y_train)

# --- 7. Make Predictions ---
# Predict the outcomes for the (scaled) test set
y_pred = knn.predict(X_test_scaled)

# --- 8. Compute Metrics ---

print("\n--- Model Evaluation (K=7) ---")

# A. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# B. Accuracy
# (TP + TN) / (All)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy:.4f} (or {accuracy*100:.2f}%)")

# C. Error Rate
# 1 - Accuracy
error_rate = 1 - accuracy
print(f"Error Rate: {error_rate:.4f} (or {error_rate*100:.2f}%)")

# D. Precision (for the '1' class, i.e., "has diabetes")
# TP / (TP + FP)
# "Of all patients we PREDICTED had diabetes, how many actually did?"
precision = precision_score(y_test, y_pred, pos_label=1)
print(f"Precision: {precision:.4f}")

# E. Recall (for the '1' class)
# TP / (TP + FN)
# "Of all patients who ACTUALLY had diabetes, how many did we find?"
recall = recall_score(y_test, y_pred, pos_label=1)
print(f"Recall: {recall:.4f}")

print("\n--- Full Classification Report ---")
# This report nicely summarizes metrics for BOTH classes (0 and 1)
print(classification_report(y_test, y_pred, target_names=['No Diabetes (0)', 'Diabetes (1)']))


# --- 9. Visualize the Confusion Matrix (Optional but Recommended) ---
plt.figure(figsize=(7, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title(f'Confusion Matrix (K={k})')
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')
plt.show()